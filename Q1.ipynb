{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "07Hb3Ko1-wnX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0jfrT-Z-9GD",
        "outputId": "a7041c60-e791-4d36-8144-55b13b9e5636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  1) Dataset preparation code\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WsSoeSMXo8n5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUvGd5M4-wnY"
      },
      "outputs": [],
      "source": [
        "google_image = \"https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&\"\n",
        "user_agent = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrPNVZal-wnY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "om3hJw94-wnY"
      },
      "outputs": [],
      "source": [
        "\n",
        "def download_images(index,name):\n",
        "    data = input('What are you looking for? ')\n",
        "    n_images = int(input('How many images do you want? '))\n",
        "    #class_id=input('Enter the class id: ')\n",
        "    print('searching...')\n",
        "\n",
        "    search_url = google_image + 'q=' + data\n",
        "\n",
        "    response = requests.get(search_url, headers=user_agent)\n",
        "\n",
        "    html = response.text\n",
        "    html_=str(html)\n",
        "    sarray=html_.split('img class=')[2]\n",
        "    print(sarray)\n",
        "    class_context=sarray[1:100]\n",
        "    class_id=class_context.split('\"')[0]\n",
        "    print('class_id: ',class_id)\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    results = soup.findAll('img', {'class': str(class_id)})\n",
        "    print('results: ', len(results))\n",
        "    count = 1\n",
        "    links = []\n",
        "    for result in results:\n",
        "        try:\n",
        "            #print(\"result: \",result)\n",
        "            link = result['src']\n",
        "            #print(\"link: \",link)\n",
        "            links.append(link)\n",
        "            count += 1\n",
        "            if(count > n_images):\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e.__class__)\n",
        "            continue\n",
        "\n",
        "    print(f\"Downloading {len(links)} images...\")\n",
        "    for i, link in enumerate(links):\n",
        "        response = requests.get(link)\n",
        "\n",
        "        image_name = saved_folder + '/'+ name+'/'+ name+'_'+str(i+index) + '.jpg'\n",
        "\n",
        "        with open(image_name, 'wb') as fh:\n",
        "            fh.write(response.content)\n",
        "        time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoRd0mzu-wnY"
      },
      "outputs": [],
      "source": [
        "\n",
        "saved_folder = 'images'\n",
        "\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(saved_folder):\n",
        "        os.mkdir(saved_folder)\n",
        "        os.mkdir(saved_folder + '/peacock')\n",
        "        os.mkdir(saved_folder + '/duck')\n",
        "    for i in range(5):\n",
        "        download_images(i*20,'peacock')\n",
        "    for i in range(5):\n",
        "        download_images(i*20,'duck')\n",
        "    #     download_images(i*20,'duck')\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ScY0vExv-wnZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, random_split,Dataset\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BmeLNi8s-wnZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ImageLabelDataset(Dataset):\n",
        "  def __init__(self, data_dir, transform=None):\n",
        "    self.data_dir = data_dir\n",
        "    self.image_paths = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, f))]\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image_path = self.image_paths[idx]\n",
        "    # Load image as RGB (mode='RGB')\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    # Assuming your labels are encoded in the filenames (modify as needed)\n",
        "    label = os.path.splitext(os.path.basename(image_path))[0].split(\"_\")[0]\n",
        "    # Convert label to integer if needed (modify as needed)\n",
        "    #print(\"LABEL: \",label)\n",
        "    if label == 'peacock':\n",
        "        label = [0,1]\n",
        "    else:\n",
        "        label = [1,0]\n",
        "    if self.transform:\n",
        "      image = self.transform(image)\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YOtgUjRD-wnZ"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/My Drive/Assignment_4_data/images/combine'\n",
        "data_transforms = transforms.Compose([\n",
        "  transforms.Resize((200,200)),  # Resize images to 256x256\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean=[0.485, 0.568, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "dataset = ImageLabelDataset(data_dir,data_transforms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xq8-cU--wnZ",
        "outputId": "7ce05e16-d4b7-4e31-cb94-da56465d00a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 200, 200])\n"
          ]
        }
      ],
      "source": [
        "print(dataset[0][0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nBk_H1vN-wnZ"
      },
      "outputs": [],
      "source": [
        "test_size = 0.2\n",
        "train_size = int(len(dataset) * (1 - test_size))\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n",
        "\n",
        "# Create training and testing loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "remVaMY2crIO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DVM7AiQu-wnZ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class VGG(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        architecture,\n",
        "        in_channels=3,\n",
        "        in_height=224,\n",
        "        in_width=224,\n",
        "        num_hidden=4096,\n",
        "        num_classes=2\n",
        "    ):\n",
        "        super(VGG, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.in_width = in_width\n",
        "        self.in_height = in_height\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_classes = num_classes\n",
        "        self.convs = self.init_convs(architecture)\n",
        "        self.fcs = self.init_fcs(architecture)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = self.fcs(x)\n",
        "        return x\n",
        "\n",
        "    def init_fcs(self, architecture):\n",
        "        pool_count = architecture.count(\"M\")\n",
        "        factor = (2 ** pool_count)\n",
        "        if (self.in_height % factor) + (self.in_width % factor) != 0:\n",
        "            raise ValueError(\n",
        "                f\"`in_height` and `in_width` must be multiples of {factor}\"\n",
        "            )\n",
        "        out_height = self.in_height // factor\n",
        "        out_width = self.in_width // factor\n",
        "        last_out_channels = next(\n",
        "            x for x in architecture[::-1] if type(x) == int\n",
        "        )\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(\n",
        "                last_out_channels * out_height * out_width,\n",
        "                self.num_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(self.num_hidden, self.num_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(self.num_hidden, self.num_classes)\n",
        "            #nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def init_convs(self, architecture):\n",
        "        layers = []\n",
        "        in_channels = self.in_channels\n",
        "\n",
        "        for x in architecture:\n",
        "            if type(x) == int:\n",
        "                out_channels = x\n",
        "                layers.extend(\n",
        "                    [\n",
        "                        nn.Conv2d(\n",
        "                            in_channels=in_channels,\n",
        "                            out_channels=out_channels,\n",
        "                            kernel_size=(3, 3),\n",
        "                            stride=(1, 1),\n",
        "                            padding=(1, 1),\n",
        "                        ),\n",
        "                        nn.BatchNorm2d(out_channels),\n",
        "                        nn.ReLU(),\n",
        "                    ]\n",
        "                )\n",
        "                in_channels = x\n",
        "            else:\n",
        "                layers.append(\n",
        "                    nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "                )\n",
        "\n",
        "        return nn.Sequential(*layers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GQPlj-Ibcvkz"
      },
      "outputs": [],
      "source": [
        "VGG_types = {\n",
        "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG13\": [64,64,\"M\",128,128,\"M\",256,256,\"M\",512,512,\"M\",512,512,\"M\",],\n",
        "    \"VGG16\": [64,64,\"M\",128,128,\"M\",256,256,256,\"M\",512,512,512,\"M\",512,512,512,\"M\",],\n",
        "    \"VGG19\": [64,64,\"M\",128,128,\"M\",256,256,256,256,\"M\",512,512,512,512,\"M\",512,512,512,512,\"M\",],\n",
        "    \"VGG1\":[32,\"M\"],\n",
        "    \"VGG3\": [32,\"M\",64,\"M\",128,\"M\"]\n",
        "}\n",
        "\n",
        "num_classes = 2\n",
        "num_epochs = 20\n",
        "total_step = len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_LkGunkkcvkz"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def train_moodel(model,train_loader,epochs,model_name):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    model.to(device)\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            # Move tensors to the configured device\n",
        "            images = images.to(device)\n",
        "            labels=torch.stack((labels[0], labels[1]),dim=1)\n",
        "            labels=labels.float()\n",
        "            #print(\"labels: \",labels)\n",
        "            labels = labels.to(device)\n",
        "            #print(\"shape of labels: \",labels.shape)\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            #print(\"shape of outputs: \",outputs.shape)\n",
        "            #print(\"outputs: \",outputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "            #final_loss=final_loss+loss.item()\n",
        "            #print(\"loss: \",loss.item())\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            del images,labels\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, train_loss))\n",
        "    end_time = time.time()\n",
        "    torch.save(model.state_dict(),f\"/content/drive/My Drive/Assignment_4_data/{model_name}.pt\")\n",
        "    print('Time: ',end_time - start_time)\n",
        "    return (end_time - start_time),train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XvqBPQX6cvkz"
      },
      "outputs": [],
      "source": [
        "def find_train_accuracy(model,train_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels=torch.stack((labels[0], labels[1]),dim=1)\n",
        "            labels=labels.float()\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            _, labels = torch.max(labels, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return (correct / total) * 100\n",
        "\n",
        "def find_test_accuracy(model,test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels=torch.stack((labels[0], labels[1]),dim=1)\n",
        "            labels=labels.float()\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            _, labels = torch.max(labels, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return (correct / total) * 100\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vgIJx3uheWsh"
      },
      "outputs": [],
      "source": [
        "model_details={\"Model_Name\":[],\"Traning_Time\":[],\"Training_Loss\":[],\"Train_Accuracy\":[],\"Test_Accuracy\":[],\"Number_Of_Parameters\":[]}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I) Training VGG 1 block model"
      ],
      "metadata": {
        "id": "VD4ae5cLphqE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ufohney-wna",
        "outputId": "80777c14-bd84-4519-a69b-63234dd6a829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Loss: 38.1904\n",
            "Epoch [2/100], Loss: 20.1055\n",
            "Epoch [3/100], Loss: 10.0322\n",
            "Epoch [4/100], Loss: 7.4360\n",
            "Epoch [5/100], Loss: 4.2223\n",
            "Epoch [6/100], Loss: 2.7058\n",
            "Epoch [7/100], Loss: 1.2219\n",
            "Epoch [8/100], Loss: 1.1971\n",
            "Epoch [9/100], Loss: 1.0267\n",
            "Epoch [10/100], Loss: 1.2297\n",
            "Epoch [11/100], Loss: 1.4437\n",
            "Epoch [12/100], Loss: 0.9336\n",
            "Epoch [13/100], Loss: 0.3458\n",
            "Epoch [14/100], Loss: 0.1755\n",
            "Epoch [15/100], Loss: 0.5947\n",
            "Epoch [16/100], Loss: 0.3628\n",
            "Epoch [17/100], Loss: 0.2865\n",
            "Epoch [18/100], Loss: 0.3806\n",
            "Epoch [19/100], Loss: 0.2772\n",
            "Epoch [20/100], Loss: 0.3133\n",
            "Epoch [21/100], Loss: 0.1175\n",
            "Epoch [22/100], Loss: 0.0435\n",
            "Epoch [23/100], Loss: 0.1487\n",
            "Epoch [24/100], Loss: 0.0298\n",
            "Epoch [25/100], Loss: 0.0342\n",
            "Epoch [26/100], Loss: 0.0129\n",
            "Epoch [27/100], Loss: 0.0842\n",
            "Epoch [28/100], Loss: 0.0664\n",
            "Epoch [29/100], Loss: 0.0367\n",
            "Epoch [30/100], Loss: 0.0236\n",
            "Epoch [31/100], Loss: 0.1904\n",
            "Epoch [32/100], Loss: 0.0317\n",
            "Epoch [33/100], Loss: 0.0698\n",
            "Epoch [34/100], Loss: 0.0552\n",
            "Epoch [35/100], Loss: 0.0357\n",
            "Epoch [36/100], Loss: 0.1250\n",
            "Epoch [37/100], Loss: 0.1658\n",
            "Epoch [38/100], Loss: 0.1092\n",
            "Epoch [39/100], Loss: 0.0418\n",
            "Epoch [40/100], Loss: 0.2027\n",
            "Epoch [41/100], Loss: 0.0432\n",
            "Epoch [42/100], Loss: 0.0232\n",
            "Epoch [43/100], Loss: 0.0201\n",
            "Epoch [44/100], Loss: 0.0368\n",
            "Epoch [45/100], Loss: 0.0231\n",
            "Epoch [46/100], Loss: 0.0165\n",
            "Epoch [47/100], Loss: 0.0372\n",
            "Epoch [48/100], Loss: 0.0025\n",
            "Epoch [49/100], Loss: 0.0032\n",
            "Epoch [50/100], Loss: 0.0589\n",
            "Epoch [51/100], Loss: 0.0000\n",
            "Epoch [52/100], Loss: 0.0058\n",
            "Epoch [53/100], Loss: 0.0063\n",
            "Epoch [54/100], Loss: 0.0102\n",
            "Epoch [55/100], Loss: 0.0560\n",
            "Epoch [56/100], Loss: 0.0411\n",
            "Epoch [57/100], Loss: 0.1057\n",
            "Epoch [58/100], Loss: 0.0805\n",
            "Epoch [59/100], Loss: 0.0183\n",
            "Epoch [60/100], Loss: 0.4690\n",
            "Epoch [61/100], Loss: 0.4414\n",
            "Epoch [62/100], Loss: 0.8632\n",
            "Epoch [63/100], Loss: 0.5691\n",
            "Epoch [64/100], Loss: 1.0655\n",
            "Epoch [65/100], Loss: 0.4473\n",
            "Epoch [66/100], Loss: 0.4892\n",
            "Epoch [67/100], Loss: 0.6282\n",
            "Epoch [68/100], Loss: 0.1013\n",
            "Epoch [69/100], Loss: 0.4814\n",
            "Epoch [70/100], Loss: 0.1428\n",
            "Epoch [71/100], Loss: 0.2036\n",
            "Epoch [72/100], Loss: 0.9476\n",
            "Epoch [73/100], Loss: 0.5195\n",
            "Epoch [74/100], Loss: 0.3629\n",
            "Epoch [75/100], Loss: 0.0721\n",
            "Epoch [76/100], Loss: 0.0769\n",
            "Epoch [77/100], Loss: 0.3414\n",
            "Epoch [78/100], Loss: 0.1082\n",
            "Epoch [79/100], Loss: 0.2362\n",
            "Epoch [80/100], Loss: 0.4682\n",
            "Epoch [81/100], Loss: 0.2401\n",
            "Epoch [82/100], Loss: 0.4864\n",
            "Epoch [83/100], Loss: 0.2983\n",
            "Epoch [84/100], Loss: 0.1145\n",
            "Epoch [85/100], Loss: 0.2054\n",
            "Epoch [86/100], Loss: 0.6192\n",
            "Epoch [87/100], Loss: 0.0703\n",
            "Epoch [88/100], Loss: 0.1235\n",
            "Epoch [89/100], Loss: 0.0740\n",
            "Epoch [90/100], Loss: 0.3540\n",
            "Epoch [91/100], Loss: 0.2977\n",
            "Epoch [92/100], Loss: 0.5155\n",
            "Epoch [93/100], Loss: 1.1712\n",
            "Epoch [94/100], Loss: 0.0901\n",
            "Epoch [95/100], Loss: 0.0158\n",
            "Epoch [96/100], Loss: 0.0044\n",
            "Epoch [97/100], Loss: 0.0703\n",
            "Epoch [98/100], Loss: 0.0910\n",
            "Epoch [99/100], Loss: 0.2293\n",
            "Epoch [100/100], Loss: 0.0627\n",
            "Time:  84.42602014541626\n",
            "Train Accuracy:  100.0\n",
            "Test Accuracy:  75.0\n",
            "Train Time:  84.42602014541626\n",
            "Loss:  0.06266023792687463\n",
            "total_params:  328733634\n"
          ]
        }
      ],
      "source": [
        "model = VGG(VGG_types[\"VGG1\"], in_channels=3, in_height=200, in_width=200, num_hidden=1024, num_classes=2)\n",
        "train_time,loss=train_moodel(model,train_loader,100,\"vgg1\")\n",
        "train_accuracy=find_train_accuracy(model,train_loader)\n",
        "test_accuracy=find_test_accuracy(model,test_loader)\n",
        "total_params=count_parameters(model)\n",
        "model_details[\"Model_Name\"].append(\"VGG 1 Block\")\n",
        "model_details[\"Traning_Time\"].append(train_time)\n",
        "model_details[\"Train_Accuracy\"].append(train_accuracy)\n",
        "model_details[\"Test_Accuracy\"].append(test_accuracy)\n",
        "model_details[\"Number_Of_Parameters\"].append(total_params)\n",
        "model_details[\"Training_Loss\"].append(loss)\n",
        "print(\"Train Accuracy: \",train_accuracy)\n",
        "print(\"Test Accuracy: \",test_accuracy)\n",
        "print(\"Train Time: \",train_time)\n",
        "print(\"Loss: \",loss)\n",
        "print(\"total_params: \",total_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II) Training VGG 3 block model"
      ],
      "metadata": {
        "id": "RVt3p6rFpv3J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL4ACUvJhAmx",
        "outputId": "ad8c7dd4-156e-4112-a7fb-95101b71d777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Loss: 14.2095\n",
            "Epoch [2/100], Loss: 6.1025\n",
            "Epoch [3/100], Loss: 3.6355\n",
            "Epoch [4/100], Loss: 1.8387\n",
            "Epoch [5/100], Loss: 1.3341\n",
            "Epoch [6/100], Loss: 0.9244\n",
            "Epoch [7/100], Loss: 0.5930\n",
            "Epoch [8/100], Loss: 0.5118\n",
            "Epoch [9/100], Loss: 0.3865\n",
            "Epoch [10/100], Loss: 0.4103\n",
            "Epoch [11/100], Loss: 0.2682\n",
            "Epoch [12/100], Loss: 0.2375\n",
            "Epoch [13/100], Loss: 0.1596\n",
            "Epoch [14/100], Loss: 0.1448\n",
            "Epoch [15/100], Loss: 0.1347\n",
            "Epoch [16/100], Loss: 0.1867\n",
            "Epoch [17/100], Loss: 0.1017\n",
            "Epoch [18/100], Loss: 0.0784\n",
            "Epoch [19/100], Loss: 0.0795\n",
            "Epoch [20/100], Loss: 0.0822\n",
            "Epoch [21/100], Loss: 0.0925\n",
            "Epoch [22/100], Loss: 0.0247\n",
            "Epoch [23/100], Loss: 0.0364\n",
            "Epoch [24/100], Loss: 0.0338\n",
            "Epoch [25/100], Loss: 0.0735\n",
            "Epoch [26/100], Loss: 0.0722\n",
            "Epoch [27/100], Loss: 0.0468\n",
            "Epoch [28/100], Loss: 0.0734\n",
            "Epoch [29/100], Loss: 0.1226\n",
            "Epoch [30/100], Loss: 0.0521\n",
            "Epoch [31/100], Loss: 0.0556\n",
            "Epoch [32/100], Loss: 0.0516\n",
            "Epoch [33/100], Loss: 0.0549\n",
            "Epoch [34/100], Loss: 0.0589\n",
            "Epoch [35/100], Loss: 0.0939\n",
            "Epoch [36/100], Loss: 0.2630\n",
            "Epoch [37/100], Loss: 0.0781\n",
            "Epoch [38/100], Loss: 0.0545\n",
            "Epoch [39/100], Loss: 0.1055\n",
            "Epoch [40/100], Loss: 0.1764\n",
            "Epoch [41/100], Loss: 0.0508\n",
            "Epoch [42/100], Loss: 0.0799\n",
            "Epoch [43/100], Loss: 0.0800\n",
            "Epoch [44/100], Loss: 0.0249\n",
            "Epoch [45/100], Loss: 0.0525\n",
            "Epoch [46/100], Loss: 0.0322\n",
            "Epoch [47/100], Loss: 0.0438\n",
            "Epoch [48/100], Loss: 0.0051\n",
            "Epoch [49/100], Loss: 0.0111\n",
            "Epoch [50/100], Loss: 0.0101\n",
            "Epoch [51/100], Loss: 0.0041\n",
            "Epoch [52/100], Loss: 0.0064\n",
            "Epoch [53/100], Loss: 0.0032\n",
            "Epoch [54/100], Loss: 0.0120\n",
            "Epoch [55/100], Loss: 0.0336\n",
            "Epoch [56/100], Loss: 0.1261\n",
            "Epoch [57/100], Loss: 0.0058\n",
            "Epoch [58/100], Loss: 0.1494\n",
            "Epoch [59/100], Loss: 0.1439\n",
            "Epoch [60/100], Loss: 0.0408\n",
            "Epoch [61/100], Loss: 0.0946\n",
            "Epoch [62/100], Loss: 0.0568\n",
            "Epoch [63/100], Loss: 0.0666\n",
            "Epoch [64/100], Loss: 0.0798\n",
            "Epoch [65/100], Loss: 0.0618\n",
            "Epoch [66/100], Loss: 0.0112\n",
            "Epoch [67/100], Loss: 0.0152\n",
            "Epoch [68/100], Loss: 0.0343\n",
            "Epoch [69/100], Loss: 0.0134\n",
            "Epoch [70/100], Loss: 0.0095\n",
            "Epoch [71/100], Loss: 0.0181\n",
            "Epoch [72/100], Loss: 0.0523\n",
            "Epoch [73/100], Loss: 0.0198\n",
            "Epoch [74/100], Loss: 0.1582\n",
            "Epoch [75/100], Loss: 0.1192\n",
            "Epoch [76/100], Loss: 0.1469\n",
            "Epoch [77/100], Loss: 0.1109\n",
            "Epoch [78/100], Loss: 0.1300\n",
            "Epoch [79/100], Loss: 0.0376\n",
            "Epoch [80/100], Loss: 0.0404\n",
            "Epoch [81/100], Loss: 0.1693\n",
            "Epoch [82/100], Loss: 0.0162\n",
            "Epoch [83/100], Loss: 0.0558\n",
            "Epoch [84/100], Loss: 0.0354\n",
            "Epoch [85/100], Loss: 0.0167\n",
            "Epoch [86/100], Loss: 0.0680\n",
            "Epoch [87/100], Loss: 0.0322\n",
            "Epoch [88/100], Loss: 0.0475\n",
            "Epoch [89/100], Loss: 0.1004\n",
            "Epoch [90/100], Loss: 0.1072\n",
            "Epoch [91/100], Loss: 0.0559\n",
            "Epoch [92/100], Loss: 0.0388\n",
            "Epoch [93/100], Loss: 0.0129\n",
            "Epoch [94/100], Loss: 0.0988\n",
            "Epoch [95/100], Loss: 0.0060\n",
            "Epoch [96/100], Loss: 0.0547\n",
            "Epoch [97/100], Loss: 0.0392\n",
            "Epoch [98/100], Loss: 0.1103\n",
            "Epoch [99/100], Loss: 0.0045\n",
            "Epoch [100/100], Loss: 0.0012\n",
            "Time:  80.80685567855835\n",
            "Train Accuracy:  100.0\n",
            "Test Accuracy:  80.0\n",
            "Train Time:  80.80685567855835\n",
            "Loss:  0.0011869202411617153\n",
            "total_params:  83066370\n"
          ]
        }
      ],
      "source": [
        "model = VGG(VGG_types[\"VGG3\"], in_channels=3, in_height=200, in_width=200, num_hidden=1024, num_classes=2)\n",
        "train_time,loss=train_moodel(model,train_loader,100,\"vgg3\")\n",
        "train_accuracy=find_train_accuracy(model,train_loader)\n",
        "test_accuracy=find_test_accuracy(model,test_loader)\n",
        "total_params=count_parameters(model)\n",
        "model_details[\"Model_Name\"].append(\"VGG 3 Block\")\n",
        "model_details[\"Traning_Time\"].append(train_time)\n",
        "model_details[\"Train_Accuracy\"].append(train_accuracy)\n",
        "model_details[\"Test_Accuracy\"].append(test_accuracy)\n",
        "model_details[\"Number_Of_Parameters\"].append(total_params)\n",
        "model_details[\"Training_Loss\"].append(loss)\n",
        "print(\"Train Accuracy: \",train_accuracy)\n",
        "print(\"Test Accuracy: \",test_accuracy)\n",
        "print(\"Train Time: \",train_time)\n",
        "print(\"Loss: \",loss)\n",
        "print(\"total_params: \",total_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW29nmNCA2e5",
        "outputId": "32e74e97-fe6d-4a2e-c036-2a20c026e2eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
            "        1, 1, 1, 0, 0, 0, 1, 0]), tensor([1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
            "        0, 0, 0, 1, 1, 1, 0, 1])]\n",
            "tensor([[ -9.4400,   9.3858],\n",
            "        [ 35.0892, -37.8104],\n",
            "        [ -3.8872,   6.7910],\n",
            "        [ -3.3864,   4.7584],\n",
            "        [ -7.7785,   6.8084],\n",
            "        [  2.2754,  -4.5363],\n",
            "        [ -7.0080,   7.1373],\n",
            "        [  5.6260,  -6.0164],\n",
            "        [  2.4081,  -1.8405],\n",
            "        [ -3.0430,  11.5041],\n",
            "        [ 43.4163, -33.8768],\n",
            "        [-14.7671,  24.9637],\n",
            "        [  3.7345,  -5.0211],\n",
            "        [ -6.1299,   9.6998],\n",
            "        [ -1.8023,   2.1509],\n",
            "        [ -0.1125,  -0.8359],\n",
            "        [ -4.1570,   5.0758],\n",
            "        [ -0.5833,   2.3651],\n",
            "        [ -0.5744,   1.7246],\n",
            "        [  1.4415,  -3.5096],\n",
            "        [ -0.2319,   1.1401],\n",
            "        [-14.9475,  26.2135],\n",
            "        [-13.7639,  17.8193],\n",
            "        [ -5.0125,   5.6471],\n",
            "        [  5.2643,  -5.8663],\n",
            "        [  0.9985,   1.9350],\n",
            "        [ -1.3630,   1.5875],\n",
            "        [ -9.2253,   8.0445],\n",
            "        [ -7.0382,   9.2849],\n",
            "        [ -6.1368,   0.6898],\n",
            "        [ 17.5745, -12.6090],\n",
            "        [  2.0441,   1.6624]], device='cuda:0')\n",
            "tensor([ 9.3858, 35.0892,  6.7910,  4.7584,  6.8084,  2.2754,  7.1373,  5.6260,\n",
            "         2.4081, 11.5041, 43.4163, 24.9637,  3.7345,  9.6998,  2.1509, -0.1125,\n",
            "         5.0758,  2.3651,  1.7246,  1.4415,  1.1401, 26.2135, 17.8193,  5.6471,\n",
            "         5.2643,  1.9350,  1.5875,  8.0445,  9.2849,  0.6898, 17.5745,  2.0441],\n",
            "       device='cuda:0')\n",
            "[tensor([0, 0, 1, 1, 1, 0, 0, 1]), tensor([1, 1, 0, 0, 0, 1, 1, 0])]\n",
            "tensor([[  8.0276,  -3.9644],\n",
            "        [-16.9114,  23.5935],\n",
            "        [ 15.4976, -25.4211],\n",
            "        [ -6.1702,   6.5904],\n",
            "        [ 11.5278, -12.9013],\n",
            "        [ -0.7994,   1.8405],\n",
            "        [ 34.6101, -41.5879],\n",
            "        [ 23.5269, -10.9372]], device='cuda:0')\n",
            "tensor([ 8.0276, 23.5935, 15.4976,  6.5904, 11.5278,  1.8405, 34.6101, 23.5269],\n",
            "       device='cuda:0')\n",
            "Accuracy of the network on the 10000 test images: 72.5 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        print(labels)\n",
        "        labels = labels[1].to(device)\n",
        "        outputs = model(images)\n",
        "        print(outputs)\n",
        "        logits, predicted = torch.max(outputs.data, 1)\n",
        "        print(logits)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvN4SSln-wna"
      },
      "outputs": [],
      "source": [
        "data_transforms_ = transforms.Compose([\n",
        "\n",
        "  transforms.ToTensor(),\n",
        "  transforms.RandomHorizontalFlip(p=1),\n",
        "  transforms.RandomVerticalFlip(p=1),\n",
        "  transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
        "  transforms.RandomRotation(degrees=(-90,90))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY_VXUZEyTI6"
      },
      "outputs": [],
      "source": [
        "# from torchvision import datasets\n",
        "src_dir=\"/content/drive/My Drive/Assignment_4_data/images/combine/\"\n",
        "dest_dir=\"/content/drive/My Drive/Assignment_4_data/images/augmented_images/\"\n",
        "# dataset = datasets.ImageFolder(root=src_dir)\n",
        "# print(dataset)\n",
        "if not os.path.exists(dest_dir):\n",
        "        os.mkdir(dest_dir)\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir(src_dir) if isfile(join(src_dir, f))]\n",
        "for file in onlyfiles:\n",
        "  image = Image.open(src_dir+file).convert('RGB')\n",
        "  image_=data_transforms_(image)\n",
        "  image_ = transforms.ToPILImage()(image_)\n",
        "  label = os.path.splitext(file)[0].split(\"_\")\n",
        "  image_.save(dest_dir+f\"{label[0]}_a_{label[1]}.jpg\")\n",
        "  image.save(dest_dir+f\"{label[0]}_{label[1]}.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZCmepU43btT"
      },
      "outputs": [],
      "source": [
        "data_transforms = transforms.Compose([\n",
        "  transforms.Resize((200,200)),  # Resize images to 256x256\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean=[0.485, 0.568, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eqti6BXHugUZ"
      },
      "outputs": [],
      "source": [
        "dataset_ = ImageLabelDataset(dest_dir,data_transforms)\n",
        "\n",
        "test_size = 0.2\n",
        "train_size = int(len(dataset) * (1 - test_size))\n",
        "train_dataset_, test_dataset_ = random_split(dataset_, [train_size, len(dataset_) - train_size])\n",
        "\n",
        "# Create training and testing loaders\n",
        "train_loader_ = torch.utils.data.DataLoader(train_dataset_, batch_size=32, shuffle=True)\n",
        "test_loader_ = torch.utils.data.DataLoader(test_dataset_, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # III) Training VGG 3 block model with data augmentation"
      ],
      "metadata": {
        "id": "XkKgwliPqDnU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMZwh0ts3jG0",
        "outputId": "bd81d37d-d34f-4024-c435-cf93b7285cd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Loss: 10.0537\n",
            "Epoch [2/100], Loss: 2.2629\n",
            "Epoch [3/100], Loss: 1.3283\n",
            "Epoch [4/100], Loss: 0.8679\n",
            "Epoch [5/100], Loss: 0.8179\n",
            "Epoch [6/100], Loss: 0.6776\n",
            "Epoch [7/100], Loss: 0.5886\n",
            "Epoch [8/100], Loss: 0.5861\n",
            "Epoch [9/100], Loss: 0.6191\n",
            "Epoch [10/100], Loss: 0.5719\n",
            "Epoch [11/100], Loss: 0.5445\n",
            "Epoch [12/100], Loss: 0.4946\n",
            "Epoch [13/100], Loss: 0.5421\n",
            "Epoch [14/100], Loss: 0.4754\n",
            "Epoch [15/100], Loss: 0.3786\n",
            "Epoch [16/100], Loss: 0.4014\n",
            "Epoch [17/100], Loss: 0.3776\n",
            "Epoch [18/100], Loss: 0.4736\n",
            "Epoch [19/100], Loss: 0.4181\n",
            "Epoch [20/100], Loss: 0.3347\n",
            "Epoch [21/100], Loss: 0.3008\n",
            "Epoch [22/100], Loss: 0.3599\n",
            "Epoch [23/100], Loss: 0.3624\n",
            "Epoch [24/100], Loss: 0.2817\n",
            "Epoch [25/100], Loss: 0.2835\n",
            "Epoch [26/100], Loss: 0.3113\n",
            "Epoch [27/100], Loss: 0.2604\n",
            "Epoch [28/100], Loss: 0.2424\n",
            "Epoch [29/100], Loss: 0.2843\n",
            "Epoch [30/100], Loss: 0.3202\n",
            "Epoch [31/100], Loss: 0.2639\n",
            "Epoch [32/100], Loss: 0.2670\n",
            "Epoch [33/100], Loss: 0.2309\n",
            "Epoch [34/100], Loss: 0.2472\n",
            "Epoch [35/100], Loss: 0.1813\n",
            "Epoch [36/100], Loss: 0.1880\n",
            "Epoch [37/100], Loss: 0.1916\n",
            "Epoch [38/100], Loss: 0.2374\n",
            "Epoch [39/100], Loss: 0.2247\n",
            "Epoch [40/100], Loss: 0.1882\n",
            "Epoch [41/100], Loss: 0.1765\n",
            "Epoch [42/100], Loss: 0.2209\n",
            "Epoch [43/100], Loss: 0.2102\n",
            "Epoch [44/100], Loss: 0.1894\n",
            "Epoch [45/100], Loss: 0.2169\n",
            "Epoch [46/100], Loss: 0.2023\n",
            "Epoch [47/100], Loss: 0.1685\n",
            "Epoch [48/100], Loss: 0.2311\n",
            "Epoch [49/100], Loss: 0.2323\n",
            "Epoch [50/100], Loss: 0.1659\n",
            "Epoch [51/100], Loss: 0.2043\n",
            "Epoch [52/100], Loss: 0.1899\n",
            "Epoch [53/100], Loss: 0.1957\n",
            "Epoch [54/100], Loss: 0.1893\n",
            "Epoch [55/100], Loss: 0.1746\n",
            "Epoch [56/100], Loss: 0.1588\n",
            "Epoch [57/100], Loss: 0.1718\n",
            "Epoch [58/100], Loss: 0.1543\n",
            "Epoch [59/100], Loss: 0.0987\n",
            "Epoch [60/100], Loss: 0.1086\n",
            "Epoch [61/100], Loss: 0.0767\n",
            "Epoch [62/100], Loss: 0.1414\n",
            "Epoch [63/100], Loss: 0.1129\n",
            "Epoch [64/100], Loss: 0.1388\n",
            "Epoch [65/100], Loss: 0.1841\n",
            "Epoch [66/100], Loss: 0.1787\n",
            "Epoch [67/100], Loss: 0.1617\n",
            "Epoch [68/100], Loss: 0.1554\n",
            "Epoch [69/100], Loss: 0.2123\n",
            "Epoch [70/100], Loss: 0.1404\n",
            "Epoch [71/100], Loss: 0.1129\n",
            "Epoch [72/100], Loss: 0.1598\n",
            "Epoch [73/100], Loss: 0.2346\n",
            "Epoch [74/100], Loss: 0.1203\n",
            "Epoch [75/100], Loss: 0.1438\n",
            "Epoch [76/100], Loss: 0.1575\n",
            "Epoch [77/100], Loss: 0.1949\n",
            "Epoch [78/100], Loss: 0.1286\n",
            "Epoch [79/100], Loss: 0.1713\n",
            "Epoch [80/100], Loss: 0.1277\n",
            "Epoch [81/100], Loss: 0.1385\n",
            "Epoch [82/100], Loss: 0.1411\n",
            "Epoch [83/100], Loss: 0.1366\n",
            "Epoch [84/100], Loss: 0.1197\n",
            "Epoch [85/100], Loss: 0.0973\n",
            "Epoch [86/100], Loss: 0.1087\n",
            "Epoch [87/100], Loss: 0.1243\n",
            "Epoch [88/100], Loss: 0.1532\n",
            "Epoch [89/100], Loss: 0.1199\n",
            "Epoch [90/100], Loss: 0.1023\n",
            "Epoch [91/100], Loss: 0.0983\n",
            "Epoch [92/100], Loss: 0.0815\n",
            "Epoch [93/100], Loss: 0.0898\n",
            "Epoch [94/100], Loss: 0.1368\n",
            "Epoch [95/100], Loss: 0.0554\n",
            "Epoch [96/100], Loss: 0.0795\n",
            "Epoch [97/100], Loss: 0.0930\n",
            "Epoch [98/100], Loss: 0.1184\n",
            "Epoch [99/100], Loss: 0.0894\n",
            "Epoch [100/100], Loss: 0.1015\n",
            "Time:  164.78158950805664\n",
            "Train Accuracy:  100.0\n",
            "Test Accuracy:  67.5\n",
            "Train Time:  164.78158950805664\n",
            "Loss:  0.10151439756155015\n",
            "total_params:  83066370\n"
          ]
        }
      ],
      "source": [
        "model = VGG(VGG_types[\"VGG3\"], in_channels=3, in_height=200, in_width=200, num_hidden=1024, num_classes=2)\n",
        "train_time,loss=train_moodel(model,train_loader_,100,\"vgg3_augmented\")\n",
        "train_accuracy=find_train_accuracy(model,train_loader_)\n",
        "test_accuracy=find_test_accuracy(model,test_loader_)\n",
        "total_params=count_parameters(model)\n",
        "model_details[\"Model_Name\"].append(\"VGG 3 Block Augmented\")\n",
        "model_details[\"Traning_Time\"].append(train_time)\n",
        "model_details[\"Train_Accuracy\"].append(train_accuracy)\n",
        "model_details[\"Test_Accuracy\"].append(test_accuracy)\n",
        "model_details[\"Number_Of_Parameters\"].append(total_params)\n",
        "model_details[\"Training_Loss\"].append(loss)\n",
        "print(\"Train Accuracy: \",train_accuracy)\n",
        "print(\"Test Accuracy: \",test_accuracy)\n",
        "print(\"Train Time: \",train_time)\n",
        "print(\"Loss: \",loss)\n",
        "print(\"total_params: \",total_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmjGTBcR5o5x",
        "outputId": "adca044f-8180-4edb-afbe-a78fc2a7aa88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Model_Name  Traning_Time  Training_Loss  Train_Accuracy  \\\n",
            "0            VGG 1 Block     84.426020       0.062660           100.0   \n",
            "1            VGG 3 Block     80.806856       0.001187           100.0   \n",
            "2  VGG 3 Block Augmented    164.781590       0.101514           100.0   \n",
            "\n",
            "   Test_Accuracy  Number_Of_Parameters  \n",
            "0           75.0             328733634  \n",
            "1           80.0              83066370  \n",
            "2           67.5              83066370  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.DataFrame(model_details,index=None)\n",
        "print(df)\n",
        "df.to_csv(\"/content/drive/My Drive/Assignment_4_data/model_details.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV) Training VGG 16 block model with transfer learning by tuning all layers(including convolution layers)"
      ],
      "metadata": {
        "id": "hXAEYBciqSNx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "EDCe8Og16d-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f561eb0a-ccda-41c8-e2d0-c043f3edda27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.7167\n",
            "Epoch [2/100], Loss: 1.5960\n",
            "Epoch [3/100], Loss: 0.8207\n",
            "Epoch [4/100], Loss: 0.6927\n",
            "Epoch [5/100], Loss: 0.6916\n",
            "Epoch [6/100], Loss: 0.6920\n",
            "Epoch [7/100], Loss: 0.6902\n",
            "Epoch [8/100], Loss: 0.6919\n",
            "Epoch [9/100], Loss: 0.6898\n",
            "Epoch [10/100], Loss: 0.6732\n",
            "Epoch [11/100], Loss: 0.6778\n",
            "Epoch [12/100], Loss: 0.6046\n",
            "Epoch [13/100], Loss: 0.5430\n",
            "Epoch [14/100], Loss: 0.5788\n",
            "Epoch [15/100], Loss: 0.5551\n",
            "Epoch [16/100], Loss: 0.5031\n",
            "Epoch [17/100], Loss: 0.3896\n",
            "Epoch [18/100], Loss: 0.2639\n",
            "Epoch [19/100], Loss: 0.3165\n",
            "Epoch [20/100], Loss: 0.2534\n",
            "Epoch [21/100], Loss: 0.1886\n",
            "Epoch [22/100], Loss: 1.4858\n",
            "Epoch [23/100], Loss: 0.8517\n",
            "Epoch [24/100], Loss: 0.6952\n",
            "Epoch [25/100], Loss: 0.6953\n",
            "Epoch [26/100], Loss: 0.6940\n",
            "Epoch [27/100], Loss: 0.6939\n",
            "Epoch [28/100], Loss: 0.6934\n",
            "Epoch [29/100], Loss: 0.6934\n",
            "Epoch [30/100], Loss: 0.6930\n",
            "Epoch [31/100], Loss: 0.6928\n",
            "Epoch [32/100], Loss: 0.6922\n",
            "Epoch [33/100], Loss: 0.6923\n",
            "Epoch [34/100], Loss: 0.6921\n",
            "Epoch [35/100], Loss: 0.6918\n",
            "Epoch [36/100], Loss: 0.6922\n",
            "Epoch [37/100], Loss: 0.6916\n",
            "Epoch [38/100], Loss: 0.6918\n",
            "Epoch [39/100], Loss: 0.6917\n",
            "Epoch [40/100], Loss: 0.6924\n",
            "Epoch [41/100], Loss: 0.6910\n",
            "Epoch [42/100], Loss: 0.6912\n",
            "Epoch [43/100], Loss: 0.6909\n",
            "Epoch [44/100], Loss: 0.6915\n",
            "Epoch [45/100], Loss: 0.6912\n",
            "Epoch [46/100], Loss: 0.6905\n",
            "Epoch [47/100], Loss: 0.6908\n",
            "Epoch [48/100], Loss: 0.6891\n",
            "Epoch [49/100], Loss: 0.6896\n",
            "Epoch [50/100], Loss: 0.6914\n",
            "Epoch [51/100], Loss: 0.6909\n",
            "Epoch [52/100], Loss: 0.6910\n",
            "Epoch [53/100], Loss: 0.6911\n",
            "Epoch [54/100], Loss: 0.6918\n",
            "Epoch [55/100], Loss: 0.6923\n",
            "Epoch [56/100], Loss: 0.6916\n",
            "Epoch [57/100], Loss: 0.6899\n",
            "Epoch [58/100], Loss: 0.6913\n",
            "Epoch [59/100], Loss: 0.6912\n",
            "Epoch [60/100], Loss: 0.6912\n",
            "Epoch [61/100], Loss: 0.6935\n",
            "Epoch [62/100], Loss: 0.6912\n",
            "Epoch [63/100], Loss: 0.6893\n",
            "Epoch [64/100], Loss: 0.6921\n",
            "Epoch [65/100], Loss: 0.6910\n",
            "Epoch [66/100], Loss: 0.6907\n",
            "Epoch [67/100], Loss: 0.6909\n",
            "Epoch [68/100], Loss: 0.6913\n",
            "Epoch [69/100], Loss: 0.6927\n",
            "Epoch [70/100], Loss: 0.6923\n",
            "Epoch [71/100], Loss: 0.6904\n",
            "Epoch [72/100], Loss: 0.6912\n",
            "Epoch [73/100], Loss: 0.6907\n",
            "Epoch [74/100], Loss: 0.6899\n",
            "Epoch [75/100], Loss: 0.6916\n",
            "Epoch [76/100], Loss: 0.6923\n",
            "Epoch [77/100], Loss: 0.6930\n",
            "Epoch [78/100], Loss: 0.6907\n",
            "Epoch [79/100], Loss: 0.6899\n",
            "Epoch [80/100], Loss: 0.6909\n",
            "Epoch [81/100], Loss: 0.6921\n",
            "Epoch [82/100], Loss: 0.6928\n",
            "Epoch [83/100], Loss: 0.6900\n",
            "Epoch [84/100], Loss: 0.6930\n",
            "Epoch [85/100], Loss: 0.6928\n",
            "Epoch [86/100], Loss: 0.6908\n",
            "Epoch [87/100], Loss: 0.6918\n",
            "Epoch [88/100], Loss: 0.6916\n",
            "Epoch [89/100], Loss: 0.6920\n",
            "Epoch [90/100], Loss: 0.6928\n",
            "Epoch [91/100], Loss: 0.6925\n",
            "Epoch [92/100], Loss: 0.6912\n",
            "Epoch [93/100], Loss: 0.6896\n",
            "Epoch [94/100], Loss: 0.6926\n",
            "Epoch [95/100], Loss: 0.6913\n",
            "Epoch [96/100], Loss: 0.6924\n",
            "Epoch [97/100], Loss: 0.6908\n",
            "Epoch [98/100], Loss: 0.6928\n",
            "Epoch [99/100], Loss: 0.6916\n",
            "Epoch [100/100], Loss: 0.6908\n",
            "Time:  177.98576045036316\n",
            "Train Accuracy:  53.125\n",
            "Test Accuracy:  37.5\n",
            "Train Time:  177.98576045036316\n",
            "Loss:  0.6907565832138062\n",
            "total_params:  41457474\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "model = models.vgg16(weights='DEFAULT')\n",
        "in_height = 224\n",
        "in_width = 224\n",
        "\n",
        "pool_count = VGG_types[\"VGG16\"].count(\"M\")\n",
        "factor = (2 ** pool_count)\n",
        "if (in_height % factor) + (in_width % factor) != 0:\n",
        "    raise ValueError(\n",
        "                f\"`in_height` and `in_width` must be multiples of {factor}\"\n",
        "    )\n",
        "out_height = in_height // factor\n",
        "out_width = in_width // factor\n",
        "last_out_channels = next(\n",
        "            x for x in VGG_types[\"VGG16\"][::-1] if type(x) == int\n",
        "    )\n",
        "model.classifier=nn.Sequential(nn.Linear(last_out_channels*out_height*out_width,1024),nn.ReLU(),nn.Dropout(p=0.5), nn.Linear(1024,1024),nn.ReLU(),nn.Dropout(p=0.5), nn.Linear(1024,2))\n",
        "train_time,loss=train_moodel(model,train_loader,100,\"vgg16_Transfer_Learning_1\")\n",
        "train_accuracy=find_train_accuracy(model,train_loader)\n",
        "test_accuracy=find_test_accuracy(model,test_loader)\n",
        "total_params=count_parameters(model)\n",
        "model_details[\"Model_Name\"].append(\"VGG 16 Transfer Learning 1\")\n",
        "model_details[\"Traning_Time\"].append(train_time)\n",
        "model_details[\"Train_Accuracy\"].append(train_accuracy)\n",
        "model_details[\"Test_Accuracy\"].append(test_accuracy)\n",
        "model_details[\"Number_Of_Parameters\"].append(total_params)\n",
        "model_details[\"Training_Loss\"].append(loss)\n",
        "print(\"Train Accuracy: \",train_accuracy)\n",
        "print(\"Test Accuracy: \",test_accuracy)\n",
        "print(\"Train Time: \",train_time)\n",
        "print(\"Loss: \",loss)\n",
        "print(\"total_params: \",total_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V) Training VGG 16 block model with transfer learning by tuning only MLP layers"
      ],
      "metadata": {
        "id": "Tkod-7UaqeDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "model = models.vgg16(weights='DEFAULT')\n",
        "in_height = 224\n",
        "in_width = 224\n",
        "\n",
        "pool_count = VGG_types[\"VGG16\"].count(\"M\")\n",
        "factor = (2 ** pool_count)\n",
        "if (in_height % factor) + (in_width % factor) != 0:\n",
        "    raise ValueError(\n",
        "                f\"`in_height` and `in_width` must be multiples of {factor}\"\n",
        "    )\n",
        "out_height = in_height // factor\n",
        "out_width = in_width // factor\n",
        "last_out_channels = next(\n",
        "            x for x in VGG_types[\"VGG16\"][::-1] if type(x) == int\n",
        "    )\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier=nn.Sequential(nn.Linear(last_out_channels*out_height*out_width,1024),nn.ReLU(),nn.Dropout(p=0.5), nn.Linear(1024,1024),nn.ReLU(),nn.Dropout(p=0.5), nn.Linear(1024,2))\n",
        "train_time,loss=train_moodel(model,train_loader,100,\"vgg16_Transfer_Learning_1\")\n",
        "train_accuracy=find_train_accuracy(model,train_loader)\n",
        "test_accuracy=find_test_accuracy(model,test_loader)\n",
        "total_params=count_parameters(model)\n",
        "model_details[\"Model_Name\"].append(\"VGG 16 Transfer Learning 1\")\n",
        "model_details[\"Traning_Time\"].append(train_time)\n",
        "model_details[\"Train_Accuracy\"].append(train_accuracy)\n",
        "model_details[\"Test_Accuracy\"].append(test_accuracy)\n",
        "model_details[\"Number_Of_Parameters\"].append(total_params)\n",
        "model_details[\"Training_Loss\"].append(loss)\n",
        "print(\"Train Accuracy: \",train_accuracy)\n",
        "print(\"Test Accuracy: \",test_accuracy)\n",
        "print(\"Train Time: \",train_time)\n",
        "print(\"Loss: \",loss)\n",
        "print(\"total_params: \",total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGV7UBzgLEPi",
        "outputId": "eda2a1a7-0ea3-4267-e2d0-3bc4d3c5c648"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 1.2495\n",
            "Epoch [2/100], Loss: 0.3315\n",
            "Epoch [3/100], Loss: 0.1070\n",
            "Epoch [4/100], Loss: 0.0274\n",
            "Epoch [5/100], Loss: 0.0171\n",
            "Epoch [6/100], Loss: 0.0025\n",
            "Epoch [7/100], Loss: 0.0006\n",
            "Epoch [8/100], Loss: 0.0006\n",
            "Epoch [9/100], Loss: 0.0001\n",
            "Epoch [10/100], Loss: 0.0002\n",
            "Epoch [11/100], Loss: 0.0000\n",
            "Epoch [12/100], Loss: 0.0002\n",
            "Epoch [13/100], Loss: 0.0004\n",
            "Epoch [14/100], Loss: 0.0000\n",
            "Epoch [15/100], Loss: 0.0000\n",
            "Epoch [16/100], Loss: 0.0000\n",
            "Epoch [17/100], Loss: 0.0000\n",
            "Epoch [18/100], Loss: 0.0000\n",
            "Epoch [19/100], Loss: 0.0001\n",
            "Epoch [20/100], Loss: 0.0000\n",
            "Epoch [21/100], Loss: 0.0000\n",
            "Epoch [22/100], Loss: 0.0000\n",
            "Epoch [23/100], Loss: 0.0000\n",
            "Epoch [24/100], Loss: 0.0000\n",
            "Epoch [25/100], Loss: 0.0000\n",
            "Epoch [26/100], Loss: 0.0000\n",
            "Epoch [27/100], Loss: 0.0000\n",
            "Epoch [28/100], Loss: 0.0000\n",
            "Epoch [29/100], Loss: 0.0000\n",
            "Epoch [30/100], Loss: 0.0000\n",
            "Epoch [31/100], Loss: 0.0000\n",
            "Epoch [32/100], Loss: 0.0000\n",
            "Epoch [33/100], Loss: 0.0000\n",
            "Epoch [34/100], Loss: 0.0000\n",
            "Epoch [35/100], Loss: 0.0000\n",
            "Epoch [36/100], Loss: 0.0000\n",
            "Epoch [37/100], Loss: 0.0000\n",
            "Epoch [38/100], Loss: 0.0000\n",
            "Epoch [39/100], Loss: 0.0000\n",
            "Epoch [40/100], Loss: 0.0000\n",
            "Epoch [41/100], Loss: 0.0000\n",
            "Epoch [42/100], Loss: 0.0000\n",
            "Epoch [43/100], Loss: 0.0000\n",
            "Epoch [44/100], Loss: 0.0000\n",
            "Epoch [45/100], Loss: 0.0000\n",
            "Epoch [46/100], Loss: 0.0000\n",
            "Epoch [47/100], Loss: 0.0000\n",
            "Epoch [48/100], Loss: 0.0000\n",
            "Epoch [49/100], Loss: 0.0000\n",
            "Epoch [50/100], Loss: 0.0000\n",
            "Epoch [51/100], Loss: 0.0000\n",
            "Epoch [52/100], Loss: 0.0000\n",
            "Epoch [53/100], Loss: 0.0000\n",
            "Epoch [54/100], Loss: 0.0000\n",
            "Epoch [55/100], Loss: 0.0000\n",
            "Epoch [56/100], Loss: 0.0000\n",
            "Epoch [57/100], Loss: 0.0000\n",
            "Epoch [58/100], Loss: 0.0000\n",
            "Epoch [59/100], Loss: 0.0000\n",
            "Epoch [60/100], Loss: 0.0000\n",
            "Epoch [61/100], Loss: 0.0000\n",
            "Epoch [62/100], Loss: 0.0000\n",
            "Epoch [63/100], Loss: 0.0000\n",
            "Epoch [64/100], Loss: 0.0000\n",
            "Epoch [65/100], Loss: 0.0000\n",
            "Epoch [66/100], Loss: 0.0000\n",
            "Epoch [67/100], Loss: 0.0000\n",
            "Epoch [68/100], Loss: 0.0000\n",
            "Epoch [69/100], Loss: 0.0000\n",
            "Epoch [70/100], Loss: 0.0000\n",
            "Epoch [71/100], Loss: 0.0000\n",
            "Epoch [72/100], Loss: 0.0000\n",
            "Epoch [73/100], Loss: 0.0000\n",
            "Epoch [74/100], Loss: 0.0000\n",
            "Epoch [75/100], Loss: 0.0000\n",
            "Epoch [76/100], Loss: 0.0000\n",
            "Epoch [77/100], Loss: 0.0000\n",
            "Epoch [78/100], Loss: 0.0000\n",
            "Epoch [79/100], Loss: 0.0000\n",
            "Epoch [80/100], Loss: 0.0000\n",
            "Epoch [81/100], Loss: 0.0000\n",
            "Epoch [82/100], Loss: 0.0000\n",
            "Epoch [83/100], Loss: 0.0000\n",
            "Epoch [84/100], Loss: 0.0000\n",
            "Epoch [85/100], Loss: 0.0000\n",
            "Epoch [86/100], Loss: 0.0000\n",
            "Epoch [87/100], Loss: 0.0000\n",
            "Epoch [88/100], Loss: 0.0000\n",
            "Epoch [89/100], Loss: 0.0000\n",
            "Epoch [90/100], Loss: 0.0000\n",
            "Epoch [91/100], Loss: 0.0000\n",
            "Epoch [92/100], Loss: 0.0000\n",
            "Epoch [93/100], Loss: 0.0000\n",
            "Epoch [94/100], Loss: 0.0000\n",
            "Epoch [95/100], Loss: 0.0000\n",
            "Epoch [96/100], Loss: 0.0000\n",
            "Epoch [97/100], Loss: 0.0000\n",
            "Epoch [98/100], Loss: 0.0000\n",
            "Epoch [99/100], Loss: 0.0000\n",
            "Epoch [100/100], Loss: 0.0000\n",
            "Time:  134.33612298965454\n",
            "Train Accuracy:  100.0\n",
            "Test Accuracy:  87.5\n",
            "Train Time:  134.33612298965454\n",
            "Loss:  9.361502179672243e-07\n",
            "total_params:  26742786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/My Drive/Assignment_4_data/model_details.csv\",index_col=False)\n",
        "df = df.drop(df.columns[0], axis=1)\n",
        "df.loc[len(df.index)]=[\"VGG 16 Transfer Learning 1\",177.98576045036316,0.6908,53.125,37.5,41457474]\n",
        "df.loc[len(df.index)]=[\"VGG 16 Transfer Learning 2\",134.33612298965454,0.0000,100.0,87.5,26742786]\n",
        "\n",
        "df.to_csv(\"/content/drive/My Drive/Assignment_4_data/model_details.csv\",index=False)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7xcnL9I7g2D6",
        "outputId": "22b1a026-0d86-45bf-9537-c6e368033785"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Model_Name  Traning_Time  Training_Loss  Train_Accuracy  \\\n",
              "0                 VGG 1 Block     84.426020       0.062660         100.000   \n",
              "1                 VGG 3 Block     80.806856       0.001187         100.000   \n",
              "2       VGG 3 Block Augmented    164.781590       0.101514         100.000   \n",
              "3  VGG 16 Transfer Learning 1    177.985760       0.690800          53.125   \n",
              "4  VGG 16 Transfer Learning 2    134.336123       0.000000         100.000   \n",
              "\n",
              "   Test_Accuracy  Number_Of_Parameters  \n",
              "0           75.0             328733634  \n",
              "1           80.0              83066370  \n",
              "2           67.5              83066370  \n",
              "3           37.5              41457474  \n",
              "4           87.5              26742786  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2c366e4-88d6-4a0e-b948-2129cb207ebd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_Name</th>\n",
              "      <th>Traning_Time</th>\n",
              "      <th>Training_Loss</th>\n",
              "      <th>Train_Accuracy</th>\n",
              "      <th>Test_Accuracy</th>\n",
              "      <th>Number_Of_Parameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VGG 1 Block</td>\n",
              "      <td>84.426020</td>\n",
              "      <td>0.062660</td>\n",
              "      <td>100.000</td>\n",
              "      <td>75.0</td>\n",
              "      <td>328733634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VGG 3 Block</td>\n",
              "      <td>80.806856</td>\n",
              "      <td>0.001187</td>\n",
              "      <td>100.000</td>\n",
              "      <td>80.0</td>\n",
              "      <td>83066370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VGG 3 Block Augmented</td>\n",
              "      <td>164.781590</td>\n",
              "      <td>0.101514</td>\n",
              "      <td>100.000</td>\n",
              "      <td>67.5</td>\n",
              "      <td>83066370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VGG 16 Transfer Learning 1</td>\n",
              "      <td>177.985760</td>\n",
              "      <td>0.690800</td>\n",
              "      <td>53.125</td>\n",
              "      <td>37.5</td>\n",
              "      <td>41457474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VGG 16 Transfer Learning 2</td>\n",
              "      <td>134.336123</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000</td>\n",
              "      <td>87.5</td>\n",
              "      <td>26742786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2c366e4-88d6-4a0e-b948-2129cb207ebd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2c366e4-88d6-4a0e-b948-2129cb207ebd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2c366e4-88d6-4a0e-b948-2129cb207ebd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea6d4f78-12ca-4fe9-b3bf-ca27a72f37f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea6d4f78-12ca-4fe9-b3bf-ca27a72f37f9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea6d4f78-12ca-4fe9-b3bf-ca27a72f37f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Model_Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"VGG 3 Block\",\n          \"VGG 16 Transfer Learning 2\",\n          \"VGG 3 Block Augmented\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Traning_Time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 44.767178030548955,\n        \"min\": 80.80685567855835,\n        \"max\": 177.98576045036316,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          80.80685567855835,\n          134.33612298965454,\n          164.78158950805664\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training_Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29361326826590056,\n        \"min\": 0.0,\n        \"max\": 0.6908,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0011869202411617,\n          0.0,\n          0.1015143975615501\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Train_Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.96313728906053,\n        \"min\": 53.125,\n        \"max\": 100.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          53.125,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test_Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.316443772081858,\n        \"min\": 37.5,\n        \"max\": 87.5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          80.0,\n          87.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Number_Of_Parameters\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 123380445,\n        \"min\": 26742786,\n        \"max\": 328733634,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          83066370,\n          26742786\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qk0RG7N1lsnV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}